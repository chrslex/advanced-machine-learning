{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation:\n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "        \n",
    "    def sigmoid_derivative(self,x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def relu(self,x):\n",
    "        return np.maximum(0,x) \n",
    "    \n",
    "    def relu_derivative(self,x):\n",
    "        return 1. * (x > 0)\n",
    "\n",
    "    def tanh(self,x):\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def tanh_derivative(self,x):\n",
    "        return 1 - x**2\n",
    "\n",
    "    def softmax(self,x):\n",
    "        e_x = np.exp(x - np.max(x))\n",
    "        return e_x / e_x.sum()\n",
    "\n",
    "    def softmax_derivative(self,x):\n",
    "        return self.softmax(x) * (1 - self.softmax(x))\n",
    "\n",
    "    def cross_entropy(self,y_true, y_pred):\n",
    "        return -np.sum(y_true * np.log(y_pred))\n",
    "\n",
    "    def cross_entropy_derivative(self,y_true, y_pred):\n",
    "        return -y_true/y_pred\n",
    "\n",
    "    def mse(self,y_true, y_pred):\n",
    "        return np.mean(np.square(y_true - y_pred))\n",
    "\n",
    "    def mse_derivative(self,y_true, y_pred):\n",
    "        return 2 * (y_pred - y_true) / y_true.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D:\n",
    "    def __init__(self, n_filters, kernel_size, stride=1, padding=0, activation='relu'):\n",
    "        self.n_filters = n_filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.activation = activation\n",
    "        self.weights = np.random.randn(n_filters, kernel_size, kernel_size) / np.sqrt(kernel_size * kernel_size)\n",
    "        self.bias = np.zeros((n_filters, 1))\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        n_filters, d_filter, h_filter, w_filter = self.weights.shape\n",
    "        n_x, d_x, h_x, w_x = input.shape\n",
    "        h_out = int((h_x - h_filter + 2 * self.padding) / self.stride + 1)\n",
    "        w_out = int((w_x - w_filter + 2 * self.padding) / self.stride + 1)\n",
    "        conv_out = np.zeros((n_x, n_filters, h_out, w_out))\n",
    "        self.input_col = self.im2col_indices(input, h_filter, w_filter, padding=self.padding, stride=self.stride)\n",
    "        self.weights_col = self.weights.reshape(n_filters, -1)\n",
    "        out = self.weights_col @ self.input_col + self.bias\n",
    "        out = out.reshape(n_filters, h_out, w_out, n_x)\n",
    "        out = out.transpose(3, 0, 1, 2)\n",
    "        conv_out = out\n",
    "        self.conv_out = conv_out\n",
    "        return self.activation(conv_out)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pool2D:\n",
    "    def __init__(self, pool_size, stride=1, padding=0, mode='max'):\n",
    "        self.pool_size = pool_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.mode = mode\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        n_x, d_x, h_x, w_x = input.shape\n",
    "        h_out = int((h_x - self.pool_size + 2 * self.padding) / self.stride + 1)\n",
    "        w_out = int((w_x - self.pool_size + 2 * self.padding) / self.stride + 1)\n",
    "        pool_out = np.zeros((n_x, d_x, h_out, w_out))\n",
    "        for i in range(h_out):\n",
    "            for j in range(w_out):\n",
    "                h_start = i * self.stride\n",
    "                h_end = h_start + self.pool_size\n",
    "                w_start = j * self.stride\n",
    "                w_end = w_start + self.pool_size\n",
    "                x_slice = input[:, :, h_start:h_end, w_start:w_end]\n",
    "                if self.mode == 'max':\n",
    "                    pool_out[:, :, i, j] = np.max(x_slice, axis=(2, 3))\n",
    "                elif self.mode == 'average':\n",
    "                    pool_out[:, :, i, j] = np.mean(x_slice, axis=(2, 3))\n",
    "        self.pool_out = pool_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    def __init__(self):\n",
    "        self.input_shape = None\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input_shape = input.shape\n",
    "        return input.reshape(input.shape[0], -1)\n",
    "\n",
    "    def backward(self, d_output):\n",
    "        return d_output.reshape(self.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense:\n",
    "    def __init__(self, input_units, output_units, activation='relu'):\n",
    "        self.weights = np.random.randn(input_units, output_units) / np.sqrt(input_units)\n",
    "        self.bias = np.zeros((1, output_units))\n",
    "        self.activation = activation\n",
    "        self.activation_func = Activation()\n",
    "        self.activation_func_name = activation\n",
    "        self.activation_func_derivative_name = activation + '_derivative'\n",
    "        self.activation_func_derivative = getattr(self.activation_func, self.activation_func_derivative_name)\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        self.output = np.dot(input, self.weights) + self.bias\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, d_output):\n",
    "        self.d_input = np.dot(d_output, self.weights.T)\n",
    "        self.d_weights = np.dot(self.input.T, d_output)\n",
    "        self.d_bias = np.sum(d_output, axis=0, keepdims=True)\n",
    "        return self.d_input\n",
    "    \n",
    "    def update(self, learning_rate):\n",
    "        self.weights -= learning_rate * self.d_weights\n",
    "        self.bias -= learning_rate * self.d_bias\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return self.weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequential model\n",
    "class Sequential:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        self.loss = None\n",
    "        self.loss_prime = None\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "        self.y = None\n",
    "        self.learning_rate = None\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        self.output = input\n",
    "        for layer in self.layers:\n",
    "            self.output = layer.forward(self.output)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, d_output):\n",
    "        for layer in reversed(self.layers):\n",
    "            d_output = layer.backward(d_output)\n",
    "        return d_output\n",
    "\n",
    "    def set(self, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "    def train(self, x_train, y_train, x_test, y_test, epochs, learning_rate, batch_size=int):\n",
    "        self.set(learning_rate=learning_rate)\n",
    "        train_loss = []\n",
    "        test_loss = []\n",
    "        for i in range(epochs):\n",
    "            print('Epoch {}/{}'.format(i + 1, epochs))\n",
    "            print('-' * 10)\n",
    "            for j in range(0, len(x_train), batch_size):\n",
    "                x_batch = x_train[j:j + batch_size]\n",
    "                y_batch = y_train[j:j + batch_size]\n",
    "                self.train_on_batch(x_batch, y_batch)\n",
    "            train_loss.append(self.evaluate(x_train, y_train))\n",
    "            test_loss.append(self.evaluate(x_test, y_test))\n",
    "            print('train loss: {}, test loss: {}'.format(train_loss[-1], test_loss[-1]))\n",
    "        return train_loss, test_loss\n",
    "        # for epoch in range(epochs):\n",
    "        #     output = self.forward(x_train)\n",
    "        #     loss = self.loss(y_train, output)\n",
    "        #     accuracy = self.accuracy(y_train, output)\n",
    "        #     d_output = self.loss_prime(y_train, output)\n",
    "        #     self.backward(d_output)\n",
    "        #     self.update()\n",
    "        #     if epoch % 10 == 0:\n",
    "        #         print('Epoch: {}, Loss: {:.3f}, Accuracy: {:.3f}'.format(epoch, loss, accuracy))\n",
    "        #         print('Test loss: {:.3f}, Test accuracy: {:.3f}'.format(self.test(x_test, y_test), self.accuracy(y_test, self.forward(x_test))))\n",
    "\n",
    "    def update(self):\n",
    "        for layer in self.layers:\n",
    "            if hasattr(layer, 'weights'):\n",
    "                layer.weights -= self.learning_rate * layer.d_weights\n",
    "            if hasattr(layer, 'bias'):\n",
    "                layer.bias -= self.learning_rate * layer.d_bias\n",
    "\n",
    "    def test(self, x_test, y_test):\n",
    "        output = self.forward(x_test)\n",
    "        loss = self.loss(y_test, output)\n",
    "        return loss\n",
    "\n",
    "    def accuracy(self, y_true, y_pred):\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        y_true = np.argmax(y_true, axis=1)\n",
    "        accuracy = np.mean(y_pred == y_true)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "----------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [386], line 44\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Create the model\u001b[39;00m\n\u001b[0;32m     36\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[0;32m     37\u001b[0m     Conv2D(\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m3\u001b[39m, stride \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39mActivation\u001b[38;5;241m.\u001b[39mrelu),\n\u001b[0;32m     38\u001b[0m     Pool2D(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m     Flatten()\n\u001b[0;32m     42\u001b[0m     ])\n\u001b[1;32m---> 44\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [385], line 35\u001b[0m, in \u001b[0;36mSequential.train\u001b[1;34m(self, x_train, y_train, x_test, y_test, epochs, learning_rate, batch_size)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, epochs))\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     36\u001b[0m     x_batch \u001b[38;5;241m=\u001b[39m x_train[j:j \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[0;32m     37\u001b[0m     y_batch \u001b[38;5;241m=\u001b[39m y_train[j:j \u001b[38;5;241m+\u001b[39m batch_size]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read images and convert them to arrays\n",
    "image_size = (100,100)\n",
    "\n",
    "def read_image_array(path):\n",
    "    path = glob.glob(path)\n",
    "    images = []\n",
    "\n",
    "    for image in path:\n",
    "        img = cv2.imread(image, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, image_size)\n",
    "        images.append(img)\n",
    "    return images\n",
    "\n",
    "cats = read_image_array('./cats/*.jpg')\n",
    "dogs = read_image_array('./dogs/*.jpg')\n",
    "\n",
    "# Make an array of 0s for cats and 1s for dogs\n",
    "X = np.array(cats + dogs)\n",
    "y = np.array([0] * len(cats) + [1] * len(dogs))\n",
    "\n",
    "# Split the data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1000)\n",
    "\n",
    "# Normalize the data\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# Reshape the data\n",
    "X_train = X_train.reshape(-1, 100, 100, 1)\n",
    "X_test = X_test.reshape(-1, 100, 100, 1)\n",
    "\n",
    "# Create the model\n",
    "model = Sequential([\n",
    "    Conv2D(32, 3, stride = 1, activation=Activation.relu),\n",
    "    Pool2D(2, 2),\n",
    "    Conv2D(64, 3, stride = 1, activation=Activation.relu),\n",
    "    Pool2D(2, 2),\n",
    "    Flatten()\n",
    "    ])\n",
    "\n",
    "model.train(X_train, y_train, X_test, y_test, 2, 0.01, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kelas Dense digunakan untuk membuat model yang lebih kompleks. Kita dapat menambahkan layer Dense setelah Flatten layer untuk membuat model yang lebih kompleks.\n",
    "# Kelas Activation digunakan untuk menambahkan fungsi aktivasi pada model. Kita dapat menambahkan fungsi aktivasi pada layer Conv2D, MaxPooling2D, dan Dense layer.\n",
    "# Kelas Dropout digunakan untuk mengurangi overfitting pada model. Kita dapat menambahkan layer Dropout setelah layer Conv2D, MaxPooling2D, dan Dense layer.\n",
    "# Kelas Flatten digunakan untuk mengubah dimensi dari hasil pooling menjadi 1 dimensi. Kita dapat menambahkan layer Flatten setelah layer MaxPooling2D.\n",
    "# Kelas Conv2D digunakan untuk membuat layer konvolusi pada model. Kita dapat menambahkan layer Conv2D setelah layer Input.\n",
    "# Kelas MaxPooling2D digunakan untuk membuat layer pooling pada model. Kita dapat menambahkan layer MaxPooling2D setelah layer Conv2D."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3d42ad487b2b2994e012ab0306cc0a65d83ea9d079e1ade1e8453053e613de7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
